
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%{{{
% Structured General Purpose Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt,a4paper]{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{hyperref}
\usepackage{hyperref}
\usepackage{float}
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkTitle} % Top left header
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ de\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule

\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continue \ldots}\nobreak
\nobreak\extramarks{#1 (suite)}{#1 continue \ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems
\newcounter{homeworkQuestionCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
\setcounter{homeworkQuestionCounter}{0} % Removes default section numbers
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\stepcounter{homeworkQuestionCounter} % Increase counter for number of problems
\renewcommand{\homeworkSectionName}{\arabic{homeworkProblemCounter} . \arabic{homeworkQuestionCounter} #1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}
   
%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{TP2} % Assignment title
\newcommand{\hmwkDueDate}{Mardi\ 16 Février\ 2016} % Due date
\newcommand{\hmwkClass}{INF6422} % Course/class
\newcommand{\hmwkClassTime}{12h} % Class/lecture time
\newcommand{\hmwkClassInstructor}{François Labrèche} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Philippe Troclet (1815208) et Alexandre Mao (1813566)} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\small{pour\ le\ \hmwkDueDate}\\
\vspace{3in}
}
\author{\textbf{\hmwkAuthorName}}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

\newpage
\tableofcontents
\newpage%}}}

%Pour mettre des images
%\begin{figure}[H]
    %\begin{center}
	%\includegraphics{Images/} 
        %\caption{Légende}
        %\label{fig:reference}
    %\end{center}
%\end{figure}

%----------------------------------------------------------------------------------------
%	Première partie
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}[\arabic{homeworkProblemCounter} Méthode statistique] % Custom section title


\begin{homeworkSection}{Régression logitique} % Section within problem 
    On procède à une régression logistique en allant dans l'onglet "classify" puis en sélectionnant "logistic" dans le menu
functions".  En laissant sa souris sur le champ "percentage split", l'aide apparaît et nous informe que cette option nous permet
de choisir de choisir le pourcentage qui sera utilisé pour entraîner le modèle, tandis que le pourcentage restant des données
permettra de tester le modèle ainsi créé. Ainsi, les $33\%$ restants serviront à tester le modèle conçu à partir de la phase
d'apprentisage.  

\begin{table}
    \begin{center}
        \resizebox{!}{.35\paperheight}{
        \input{Tableau/coefficients.tex} 
    }
        \caption{Les coefficients pour les différentes variables}
        \label{tab:coeflogit}
    \end{center}
\end{table}

\begin{table}
    \begin{center}
        \resizebox{!}{.35\paperheight}{
        \input{Tableau/oddRatio.tex} 
    }
        \caption{Les odd Ratio des différentes variables}
        \label{tab:oddRatiologit}
    \end{center}
\end{table}

Sur les tableaux \ref{tab:coeflogit} et \ref{tab:oddRatiologit}, on peut voir (dans cet ordre) les coefficients et les odd ratio
obtenus via la régression logistique. Il convient d'expliquer le sens de ces valeurs.
Rappelons que la régression logistique repose sur l'hypothèse que la valeur $\log{\frac{P(Y=1|X)}{1-P(Y=1|X)}}$ (où $Y$ caractérise si le
mail est du spam, c'est la variable dépendante et X est l'ensemble des variables dépendantes), peut s'écrire comme une
combinaisons affine des différentes variables indépendantes (il s'agit ici des fréquences des différents mots) i.e on a une
relation de la forme:
\[
    \log{\frac{P(Y=1|X)}{1-P(Y=1|X)}} =  \alpha_0 + \sum_{i = 1}^{i = N} \alpha_i \cdot x_i
\]
Dans cette équation, les $ \alpha_i$ sont les coefficients de la régression. De manière générale, pour un événement de probabilité
$p$, l'odd associé est $\frac{p}{1-p}$. L'odd ratio est alors le ratio de deux odd celui associé à la probabilité qu'un événement
1 se produise sachant qu'un autre événement 2 s'est produit, sur celui que l'événement 2 ne se produise pas. Dans le cas présent,
l'odd ratio associé à une variable indépendante est l'exponentielle
du coefficient de cette même variable dans la régression logistique. On distingue en général trois cas de figure:
\begin{enumerate}
        \item $odd ratio = 1$ la variable est indépendante du phénomène
        \item $odd ratio < 1$ dès que la variable augmente, la probabilité que $Y=1$ diminue
        \item $odd ratio > 1$ dès que la variable augmente, la probabilité que $Y=1$ augmente
\end{enumerate}
(Ces résultats sont des propriétés de la régression logistique). 
Ainsi, on peut voir qu'un mail possédant les mots \textit{conference} et \textit{meeting} a peu de chance d'être un spam alors
qu'un mail contenant le mot \textit{order} ou \textit{adresses} a plus de chance d'être du spam.

\end{homeworkSection}

%--------------------------------------------

\begin{homeworkSection}{Étude du Modèle} % Section within problem

Pour notre modèle de régression linéaire, on a : 
\begin{enumerate} 
    \item Un taux de vrai positif de 0.891 pour les spams et un taux de vrai positif de 0.954 pour les mails non-spam (la moyenne
étant de 0.929). Le taux de vrai positif représente les mails qui ont été déclarés comme appartenant à une certaine catégorie et
qui appartienne réellement à cette catégorie. 
    \item Un taux de faux positifs désigne la proportion de mails d'une catégorie qui a été désignée à tort comme appartenant à
cette catégorie. Dans le cas présent, on a un taux de faux positif de 0.046 pour les spam et de 0.109 pour les mails normaux.
    \item La précision mesure à quel point le résultat d'estimateur devrait être proche de
la valeur à estimer. (C'est-à-dire quelles sont les chances pour un mail identifié comme appartenant à une catégorie de
réellement appartenir à une catégorie). Ici, elle se calcule en divisant le nombre de mails qui appartiennent réellement à une catégorie par le
nombre de mails dont le test estime qu'ils appartiennent à cette catégorie. On a une précision de 0.926 pour les spams et de 0.931 pour les mails
normaux  soit une moyenne de 0.929. 
    \item La sensibilité est le nombre de mails correctement identifiés d'une catégorie sur le cardinal de cette catégorie. La
sensibilité mesure donc à quel point les résultats sont proches de la réalité (Le nombre de mails identifiés comme membre
d'une catégorie est proche du nombre réel). Une sensibilité (recall) de 0.891 pour les spam de
0.954 pour les mails classiques, ce qui donne une moyenne de  0.929. On remarque que la sensibilité a les mêmes valeurs que les
true positives 
    \item La F-Measure se calcule par la formule $2 \cdot \frac{recall * precision}{recall +
        precision}$. Ici elle vaut pour le spam (respectivement pour les mails normaux) 0.908 (respectivement 0.942). Cette valeur
sert principalement de métrique pour comparer les performances de différents algorithmes, plus sa valeur est élevée plus
l'algorithme est supposé performant. En revanche, il n'y a pas vraiment d'interprétation pratique de cette valeur.
    \item une aire sous la courbe (ROC area) de 0.971. Cette valeur mesure la performance de notre modèle. Elle désigne l'aire
sous la courbe lorsque l'on trace le taux de vrais positifs en fonction de taux de faux positifs pour un classificateur
donné (dans le cas présent on peut prendre une valeur seuil de la fréquence de certains mots). L'idée est que plus cette valeur
est élevée meilleur est le test. En effet, plus cette valeur est élevée, plus la courbe s'éloigne de la droite identité et donc
plus elle se rapproche du point (0,1) qui caractérise un test parfait.
%A voir https://fr.wikipedia.org/wiki/Receiver_Operating_Characteristic
        \item La matrice de confusion est visible sur le tableau \ref{tab:matrix}, les deux premières colonnes caractérisent les
résultats obtenus lors des tests. La première colonne correspond aux mails détectés comme spam, tandis que la seconde correspond
aux mails normaux. La première ligne représente les mails étant réellement du spam, tandis que la seconde caractérise les mails
légitimes.

Nous pouvons voir que notre modèle possède une précision assez bonne, de plus de 90\%(voir paragraphe 3 de l'article A SURVEY OF LEARNING-BASED TECHNIQUES OF EMAIL SPAM FILTERING). Au niveau du taux de vrai positif et de faux positif, nous pouvons que dans le premier cas, notre valeur moyenne est a peu près à 93\% et pour la seconde, la valeur moyenne étant inférieur à 9\%. Nous arrivons donc avec cette méthode à filtrer une grosse partie des spams en se trompant que légèrement pour sur la nature des mails. Au niveau des valeurs de F-Measure, ROC area, et de sensibilité, nous avons des valeurs que nous pouvons considérer comme assez "haute", mais que nous utiliserons comme valeurs de comparaisons avec les autres méthodes utilisées dans ce TP.
\begin{table}
    \begin{center}
        \input{Tableau/matrix.tex} 
        \caption{Matrice de confusion}
        \label{tab:matrix}
    \end{center}
\end{table}
\end{enumerate} 


\end{homeworkSection}

\begin{homeworkSection}{Tokenization attack} 
    Un exemple de contre-mesure de type Tokenization attack qu'un spammeur pourrait
    facilement utiliser afin de contourner un filtre basé uniquement sur la fréquence d'apparition de certains mots est de
    permuter la place de certaines lettres dans certains mots, ou de créer de manière volontaire des fautes d'orthographes qui
    n'altéreront pas la signification du texte. Nous pouvons aussi utiliser des lettres similaires ayant un code ASCII différent.  Pour le message suivant nous pourrions avoir le résultat :

{\it
DEAR RECEIVER,

You have just recieved a Talban virus. Since we re not so technlogoicaly advanced in Afganistan, this is a MANUAL vrus. Please
click on this lnk(http://clickeme.com) to delte all the files on your hard disk and send this mal to evryone u know. 
}
%voir article http://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html

Notons que même si cette stratégie est utilisée plusieurs fois par mot, le texte reste lisible. Et donc, malgré une orthographe
douteuse, le mail reste compréhensible et ne gêne donc pas l'effet du spam. De ce fait, les personnes qui seraient tombées dans le
piège avec un mail bien orthographié, tomberont probablement dans le piège pour la version mal orthographiée.

Par ailleurs, s'il ne manque que quelques lettres, cela pourra être interprété comme des fautes de frappe, et donc ne nuirait pas au
but du spam.

\end{homeworkSection}
%--------------------------------------------

\end{homeworkProblem}

%---------------------------------------------------------------------------------------- PROBLEM 3
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}[\arabic{homeworkProblemCounter} Apprentissage automatique] % Roman numerals 
\begin{homeworkSection}{Caractéristiques des méthodes} % Using the problem name elsewhere 
    Parmi les méthodes d'apprentissage automatique les plus courantes, nous avons : 
\begin{enumerate} 
    \item L'apprentissage non-supervisé consiste à donner un jeu de données à l'ordinateur, ces données seront brutes,
c'est-à-dire qu'elles n'auront pas été classifiées ni étudiées. Il n'y aura pas non plus de notion de classe qui sera communiquée
à l'ordinateur. L'ordinateur devra lui-même extraire des classes des données et ce sera à l'homme d'interpréter le sens de ces
classes. Dans le cas présent, c'est comme si on avait une base de mails non-analysés, et qu'on demandait à l'ordinateur d'en
extraire des catégories.
%définition de wikipédia \url{https://fr.wikipedia.org/wiki/Apprentissage_non_supervisé} 
            \item L'apprentissage semi-supervisé est une classe de techniques d'apprentissage automatique qui utilise un
ensemble de données étiquetées et non-étiquetés. (Au contraire des deux autres méthodes qui utilisent soit l'un
soit l'autre). Il a été démontré que l'utilisation combinée des données étiquetées et non étiquetées, permet d'améliorer
significativement la qualité de l'apprentissage. Notons que l'utilisation de données non étiquetées permet de réduire
l'intervention humaine: étiqueter de grands jeux de données peut être fastidieux
%wikipédia https://fr.wikipedia.org/wiki/Apprentissage_semi-supervis%C3%A9 
        \item L'apprentissage supervisé consiste à répartir des données dans des classes pré-existantes (issues de l'intuition).
En se basant sur des exemples connus issus de différentes classes. Cela se fait en deux phases, une d'apprentissage où l'on
extrait un modèle pour les membres des différentes classes, puis une seconde phase où on prédit la classe de nouvelles données.
(On notera que la régression logistique faite en auparavant appartient à cette catégorie).
\end{enumerate}
%--------------------------------------------

\end{homeworkSection}

%--------------------------------------------

\begin{homeworkSection}{Classification naïve bayésienne}
    Les méthodes de classification de type naïve bayésienne se base sur l'inférence bayésienne. \'A partir d'une loi de probabilité à
priori, généralement uniforme, (C'est à dire qu'on suppose qu'un mail a autant de chances d'être du spam que d'être légitime). on
déduit des probabilités a posteriori via la formule de Bayes ($P(A|B) = \frac{P(A \cap B)}{P(B)}$). Dans le cas présent, sachant
qu'on a plusieurs variables explicatives (les fréquences), le modèle considère que ces événements sont indépendants, d'où son
appellation "naïve". Il est sera donc naturel de constater une erreur dans les résultats obtenus. (Les mots d'une phrase étant
rarement indépendants).
\newline


Pour notre modèle de classification naïve bayésienne, on a :
\begin{itemize} 
    \item Un taux de vrai positif de 0.945 pour les spams et un taux de vrai positif de 0.673 pour les mails non-spam
            (la moyenne étant de 0.78), le taux de vrai positif. Il représente les taux de mails qui ont été considérés comme étant des spams et qui sont réellement des mails 
    \item un taux de faux positif de 0.327 qui est le taux de mail considérés
            comme des spams mais à tort. Et un taux de faux positif de 0.0055 pour les mails considérés comme des non-spams alors
        qu'ils le sont. moyenne de 0.163 
    \item une précision de (0.653 pour les spams/0.949 pour les mails normaux) 0.832 de
            moyenne.  La précision correspond au rapport entre le nombre de mails détecté comme des spams et qui le sont
            effectivement, sur le nombre total de mails qui sont des spams pour la première valeur. Pour la seconde c'est la même
            chose mais avec les mails qui ne sont pas des spams.  La moyenne se fait donc sur le nombre de mails qui ont été bien
        catégorisé sur le nombre total de mail.  
    \item une sensibilité (recall) de (0.945/0.673) 0.78. On remarque que la
        sensibilité a les mêmes valeurs que les true positives 
    \item un F-Measure de (0.772/0.787) 0.781. Ces valeurs ont l'air
            d'être la moyenne entre la précision et la sensibilité. %définition à revoir 
        \item une aire sous la courbe (ROC area)
        de 0.935. Cette valeur mesure la performance de notre modèle 
    \item Une matrice de confusion que nous pouvons voir dans la Table 5.
%A voir https://fr.wikipedia.org/wiki/Receiver_Operating_Characteristic
Nous pouvons voir que les valeurs que nous avons pour le taux de vrai positif, notre precision, ne sont pas bonnes au niveau de la valeur. On ne dépasse pas les 85\%. Alors que le taux de faux positif quant à lui à une valeur beaucoup trop élevée pour être acceptable.(On a un niveau d'erreur trop élevé).
Comparativement au précédent modèle, ce que nous pouvons voir, c'est qu'au niveau des moyennes, ce modèle à des résultats moins bon
que le modèle avec la régression linéaire malgré le fait qu'il détecte mieux les spams, il détecte en revanche un part très
importante des mails normaux comme des spams (1/3 environ), ce qui n'est pas une bonne chose du tout et pourrait être
préjudiciable aux utilisateurs. Si nous comparons les valeurs de sensibilité, de F-Measure, et de ROC area, le modèle utilisant la régression linéaire possède des valeurs plus haute que celle de la méthode naïve bayésienne. Nous pouvons donc en déduire que le premier modèle est plus performant que ce second modèle.
Notons également que de part l'hypothèse de base(l'indépendance), ce modèle ne pourra jamais
donner des résultats parfaits quelle que soit sa base de tests.
\end{itemize} 

\begin{table}[H]
    \begin{center}
        \input{Tableau/naiveBayesperf.tex} 
        \caption{les résultats de la classification naïve bayésienne}
        \label{tab:naibres}
    \end{center}
\end{table}
\begin{table}[H]
    \begin{center}
        \input{Tableau/matrixBayes.tex} 
        \caption{Matrice de confusion pour la classification naïve bayésienne}
        \label{tab:matrixBayes}
    \end{center}
\end{table}
\end{homeworkSection}

\begin{homeworkSection}{Les arbres décisionnels} 
    Cette méthode de classification se base sur la création d'arbres représentant l'espace de la base de tests. \'A chaque nœud
correspond une partie cet espace, tous les nœuds fils de ce nœud seront des divisions de cet espace. (Si un nœud a $n$
nœuds son espace sera divisé en $n$ parties). (Le résultat est alors la catégorie dominante dans la feuille à laquelle le mail
appartient). Le modèle crée plusieurs arbres (chacun associé à une partition des données) et
fait la moyenne des résultats des différents arbres pour en déduire un résultat final. Notons que cette méthode est connue pour
pouvoir facilement s'adapter à de grands espaces de données.
    \newline
    Pour notre modèle de random forest, on a : 
\begin{itemize} 
    \item Un taux de vrai
            positif de 0.927 pour les spams et un taux de vrai positif de 0.963 pour les mails non-spam (la moyenne étant de
            0.949), le taux de vrai positif. Il représente les taux de mails qui ont été considéré comme étant des spams et qui
            sont réellement des mails
    \item un taux de faux positif de 0.037 qui est le taux de mail considérés comme des spams
            mais à tort. Et un taux de faux positif de 0.073 pour les mails considérés comme des non-spam alors qu'ils le sont.
        moyenne de 0.059 
    \item une précision de (0.927 pour les spams/0.963 pour les mails normaux) 0.949 de moyenne.  La
            précision correspond au rapport entre le nombre de mails détecté comme des spams et qui le sont effectivement, sur le
            nombre total de mail qui sont des spams pour la première valeur. Pour la seconde c'est la même chose mais avec les
            mails qui ne sont pas des spams.  La moyenne se fait donc sur le nombre de mails qui ont été bien catégorisé sur le
        nombre total de mail.  
    \item une sensibilité (recall) de (0.927/0.963) 0.949. On remarque que la sensibilité a les mêmes
        valeurs que les true positives
    \item un F-Measure de (0.935/0.958) 0.949. Ces valeurs ont l'air d'être la moyenne entre la
            précision et la sensibilité. %définition à revoir
    \item une aire sous la courbe (ROC area) de 0.987. Cette valeur
        mesure la performance de notre modèle 
    \item Nous pouvons voir la matrice de confusion de ce modèle au niveau de la table 7
%A voir https://fr.wikipedia.org/wiki/Receiver_Operating_Characteristic
Nous pouvons voir tout d'abord au niveau des valeurs de ce modèle que nous possédons de bonnes valeurs, un taux de vrai positif à plus de 94\% de moyenne, un taux de faux positif moyen à environ 6\% et une précision de plus de 94%\.
Comparativement aux deux précédents modèles, ce que nous pouvons voir, est que les valeurs pour les différents élément sont toutes
meilleures, notamment au niveau de la sensibilité, de la valeur de F-Measure et de la valeur de ROC Area. Comme nous avions dit que ces valeurs étaient utilisées pour la comparaison de différents modèles, nous pouvons donc en déduire que ce modèle est préférable au vue de ces valeurs.
\end{itemize} 
\begin{table}[H]
    \begin{center}
        \input{Tableau/rdmForstPerf.tex} 
        \caption{les résultats de la classification random forest}
        \label{tab:naibres}
    \end{center}
\end{table}
\begin{table}[H]
    \begin{center}
        \input{Tableau/matrixRandonForest.tex} 
        \caption{Matrice de confusion pour la classification random forest}
        \label{tab:matrixRndFrst}
    \end{center}
\end{table}
\end{homeworkSection}

\begin{homeworkSection}{Contre-mesures \textit{Statistical Attack}} 
    Un exemple de contre-mesure de type Statistical attack qu'un spammeur
pourrait utiliser afin d'échapper à un filtre basé sur la fréquence des mots en utilisant une méthode d'apprentissage
automatique est l'utilisation de synonymes pour les mots. Le spammeur pourrait avoir une liste de synonymes ou une liste avec différentes phrases ayant un sens global similaire
qu'il choisirait aléatoirement au moment d'envoyer le mail. Il s'agirait ainsi d'éviter la répétition des mots "louches", repéré comme souvent utilisé dans les spam,
ce qui rendrait le mail plus dur à identifier en tant que spam.
Une autre méthode serait de rajouter un bourrage de texte à la fin du mail afin de noyer les fréquences des mots "coupables" par
un grands nombre de mots tirés au hasard.
\newline

Les contres-mesures possibles seraient d'utiliser des tokens et non plus des mots pour calculer les fréquences. Chaque token
représenterait une classe de mots tous synonymes. Puis de vérifier si le mail a une taille raisonnable, et s'il ne s'agit de
répétitions de mêmes mots. (Ce qui permettrait de déjouer la technique de bourrage). 
    % A compléter Une solution qui permettrait de contrecarrer cette contre-mesure est : ....
\end{homeworkSection} 
\end{homeworkProblem}

%--------------------------------------------

\begin{homeworkProblem}[\arabic{homeworkProblemCounter} Apprentissage automatique] % Roman numerals

\begin{homeworkSection}{Comparaison des résultats} 
    Au niveau des résultats, nous avons les moins bonne valeurs pour la méthode de classification naïve bayésienne, les valeurs de la méthode de régression linéaire sont meilleurs mais le dernier modèle utilisé nous fournit les meilleurs résultat au niveau valeurs moyennes(mais au niveau du taux de vrai positif  pour la détection de mails classiques, le taux de faux positif pour le mail, la précision pour les spam et la sensibilité pour les mails classiques). Nous pouvons voir que la régression linéaire nous
fournit un modèle correcte que nous pouvons penser tout même assez bon, le modèle de classification naïve bayésienne nous fournit un modèle non pertinent car il considère
plus de 30\% des mails comme spam alors qu'ils ne le sont pas, il n'est donc pas exploitable en réalité car trop préjudiciable pour des usagers. Et le modèle de forêts d'arbres décisionnels nous donne le
meilleur résultat, on peut donc penser que c'est un bon modèle, ou tout du moins, un bon modèle pour notre jeu de données.  C'est donc cette méthode qui semblent donner les meilleures performances pour le jeu de données spambase.

Références :
\begin{itemize}
\item Apprentissage supervisé, Fabrice Rossi

(\url{http://apiacoa.org/publications/teaching/data-mining/supervised.pdf})
\item Supervised Learning Workflow and Algorithms, site MathWorks 
(\url{http://fr.mathworks.com/help/stats/supervised-learning-machine-learning-workflow-and-algorithms.html})
\item Apprentissage supervisé, site Wikipédia

(\url{https://fr.wikipedia.org/wiki/Apprentissage_supervis%C3%A9})
\end{itemize}
\end{homeworkSection}

\begin{homeworkSection}{Avantage et inconvénient d'un modèle non supervisé} 
Un avantage de l'utilisation des filtres basés sur l'apprentissage machine supervisé est que l'on est confiant quand à la répartition des données que nous allons avoir. En effet avec l'apprentissage machine supervisé, nous fournissons un jeu de données test connus sur lesquels nous connaissons les résultats et donc les classes sur lesquelles ils sont répartis, nous pouvons donc vérifier l'efficacité de notre filtre sur la détection de spams. Cependant l'inconvénient d'un tel modèle est que nous devons fournir les données d'entrées sur lesquelles nous devons déterminé la classe auquel elles appartiennent. En estimant que pour créer un modèle solide et fiable, il nous faudrait une quantité de données en entrée que nous avons déjà traité en quantité suffisante, diversifiée et donc assez importante, ce procédé demande donc du temps pour la préparation et la classification des données d'entrées.
 
Au niveau de l'apprentissage machine non supervisé, il est intéressant de l'utiliser dans le cas où nous voudrions répartir en différentes classes des données volumineuses sur lesquelles nous n'avons a priori pas beaucoup d'informations. Cette méthode, nous permet donc d'avoir un premier tri, avec une intervention humaine relativement faible, qui se déroulera à la fin du processus pour interpréter les résultats de notre filtre. Nous pouvons aussi optimiser un critère visant à regrouper nos données dans des classes le plus homogène possibles mais distinctes entre elles. L'inconvénient d'une telle méthode est que nous ne savons pas à quoi nous attendre au niveau du résultat, étant donné que nous n'avons que peu voir par d'idées sur comment seront répartis les données en entrée. Nous pouvons des répartitions des données intéressantes voire très bonnes comme le contraire, où nous aurons une répartition des données dont nous ne verrons pas forcément le lien ou une répartition des données dans des classes qui ne nous intéresse pas.

Références :
\begin{itemize}
	\item Apprentissage non supervisé, Site Wikipédia
	
(\url{https://fr.wikipedia.org/wiki/Apprentissage_non_supervis%C3%A9})
	\item Apprentissage non supervisé, Hélène Milhem
	
(\url{http://moodle.insa-toulouse.fr/pluginfile.php/30346/mod_resource/content/0/ApprentissageNonSupervise.pdf})
	\item Apprentissage non-supervisé appliqué à l’analyse de logs de proxy, Philippe Beraud
	
(\url{http://blogs.msdn.com/b/big_data_france/archive/2014/06/06/apprentissage-non-supervis-233-appliqu-233-224-l-analyse-de-logs-de-proxy.aspx})
\end{itemize}

\end{homeworkSection}

\begin{homeworkSection}{Amélioration de la performance} 
    En plus de la fréquence, nous pourrions considérer, une système de réputation sur les adresses sources des mails, ce qui
reprendrait les principes des listes noires, blanches et grises. Les adresses identifiées par l'utilisateur comme étant auteures
de spam seraient dans la liste noire et l'utilisateur ne verrait plus les mails associés à ces adresses. \'A l'inverse il
recevrait toujours ceux de la liste blanche quel que soit leur contenu. Les adresses ne figurant sur aucune des deux listes
précédentes seraient considérées dans la liste grise et devrait envoyer plusieurs fois leur mail afin que l'utilisateur final les
reçoive. (On considère que les spam envoient rarement plusieurs fois le même message aux utilisateurs). On pourrait également
envisager un filtrage sur le contenu, si le message contient un exécutable ou une archive protégée par un mot de passe (dont on ne
pourrait analyser le contenu), il serait refusé afin de limiter la propagation de spam destiné à propager des virus. D'autant plus
qu'un utilisateur normal ne devrait pas envoyer d'exécutable par mail (C'est ce qui est fait notamment dans la messagerie de google, qui ne permet pas d'envoyer directement un exécutable). De même, on pourrait refuser les mails contenant des images
dans le corps du texte, car il pourrait s'agir d'une tentative d'un spammeur de dissimuler son texte au sein d'images (qui sont
plus dures à analyser que du texte pur). De plus, un utilisateur normal pourra juste mettre ses images en pièces-jointes. Enfin,
on pourra bloquer les mails ayant une large liste de destinaires, car ceux-ci sont susceptibles d'être du spam.
Nous pourrions aussi filtrer les mails selon leur adresse IP émettrice pour avoir une idée de leur provenance (pays émetteur notamment) et le propriétaire de cette adresse. Nous pouvons aussi considérer la configuration du serveur émetteur, et vérifier si le protocole SMTP s'est bien déroulé, s'il y a bien eu le respect de l'acquittement. On peut ainsi vérifier ainsi la qualité du serveur émetteur.
Et nous pouvons aussi analyser l'en-tête du mail, en étudiant les récepteurs, le sujet du message, et la date d'envoi.

Références :
\begin{itemize}
\item Sélection de Caractéristiques pour le Filtrage de Spams, Kamilia MENGHOUR, Labiba SOUICI-MESLATI

(\url{https://www.researchgate.net/publication/220761239_Selection_de_Caracteristiques_pour_le_Filtrage_de_Spams}))\item Comment un spam est détecté ?, Stephane Manhes

(\url{http://www.altospam.com/actualite/2007/07/comment-un-spam-est-detecte/})
\item Panorama des technologies antispam, OKTEY

(\url{http://www.altospam.com/fr/panorama-des-technologies-antispam.php})
\end{itemize}
\end{homeworkSection}


\end{homeworkProblem}

\end{document}
